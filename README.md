# FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de InformÃ¡tica e AdmnistraÃ§Ã£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# PROJETO FASE 6 â€“ O COMEÃ‡O DA REDE NEURAL

## Nome do grupo

## Grupo 11

## ğŸ‘¨â€ğŸ“ Integrantes: 
- <a href="https://www.linkedin.com/in/caiorcastro/">Caio Rodrigues Castro</a> 
- <a href="https://www.linkedin.com/in/celeste-leite-dos-santos-66352a24b/">Celeste Leite dos Santos</a> 
- <a href="https://www.linkedin.com/in/digitalmanagerfelipesoares/">Felipe Soares Nascimento</a>
- <a href="https://www.linkedin.com/in//">Wellington Nascimento de Brito</a>



## ğŸ‘©â€ğŸ« Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/in/leonardoorabona/">Leonardo Ruiz Orabona</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/in/profandregodoi/">AndrÃ© Godoi Chiovato</a>


## ğŸ“œ DescriÃ§Ã£o

Este projeto tem como objetivo aplicar e comparar diferentes abordagens de VisÃ£o Computacional na identificaÃ§Ã£o de alimentos (cenoura e batata), com foco em tarefas como classificaÃ§Ã£o e detecÃ§Ã£o de objetos. As soluÃ§Ãµes exploradas incluem:

- YOLOv8 Customizado (detecÃ§Ã£o e localizaÃ§Ã£o)
- YOLOv8 PrÃ©-treinado (sem fine-tuning)
- CNN do zero (classificaÃ§Ã£o)

Foram avaliadas acurÃ¡cia, tempo de treinamento, facilidade de implementaÃ§Ã£o e desempenho na inferÃªncia, considerando cenÃ¡rios reais como automaÃ§Ã£o agrÃ­cola.


## ğŸ“ Estrutura de pastas

- ğŸ”¬ **Notebook com a implementaÃ§Ã£o completa**: [Clique aqui para acessar o notebook no Colab](./src/FelipeSoares_Nascimento_RM560151_pbl_fase6_2.ipynb)
- ğŸ¥ **VÃ­deo demonstrativo**: [Assista aqui](LINK_DO_VÃDEO) 
- ğŸ“ **Dataset utilizado**: [Link para download do dataset](https://drive.google.com/file/d/1Yj9sYI9tum4c2c6ysYFp4-Cw4MS6WZCg/view?usp=drive_link)


## ğŸ”§ Como executar o cÃ³digo

### PrÃ©-requisitos:
- Google Colab ou ambiente Jupyter
- GPU recomendada para treinamento (T4 no Colab)
- Bibliotecas:
  - `ultralytics`
  - `torch`
  - `opencv-python`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`

(InstalaÃ§Ã£o automÃ¡tica via `pip install` dentro do notebook)

### Passo a passo:
1. Acesse o [notebook](https://colab.research.google.com/drive/1a4WzYzeUrFlogsQUIHSOoyc4NrMn-Juk?usp=sharing)
2. Monte o Google Drive com o dataset (instruÃ§Ã£o incluÃ­da no notebook).
3. [Link para download do dataset](https://drive.google.com/file/d/1Yj9sYI9tum4c2c6ysYFp4-Cw4MS6WZCg/view?usp=drive_link)

  - faÃ§a o download do arquivo zip "dataset-cenoura-batata.zip" e sua no seu drive o arquivo "dataset"
4. Execute as cÃ©lulas em sequÃªncia:
   - PreparaÃ§Ã£o dos dados
   - Treinamento dos modelos
   - InferÃªncia e avaliaÃ§Ã£o
5. Visualize os resultados diretamente nas saÃ­das do notebook com mÃ©tricas e imagens inferidas.

## ğŸ“Š Resultados comparativo das Abordagens


| Abordagem        | Facilidade | PrecisÃ£o | Tempo Treinamento | Tempo InferÃªncia |
|------------------|------------|----------|-------------------|------------------|
| YOLO Customizado | MÃ©dia      | 0,90     | 1h (60 Ã©pocas)    | 0,1s/imagem      |
| YOLO PadrÃ£o      | Alta       | 0,00     | 0s                | 0,1s/imagem      |
| CNN do Zero      | MÃ©dia      | 0,85     | 15min             | 0,05s/

## ğŸ¯ ConclusÃ£o
Nos nossos testes, vimos diferenÃ§as claras entre as abordagens que usamos para identificar alimentos, especialmente batatas e cenouras.

O YOLO customizado foi o que teve o melhor desempenho. Ele conseguiu identificar e localizar os objetos com bastante precisÃ£o, atingindo cerca de 92% de acurÃ¡cia no nosso conjunto de teste. Como ele desenha caixas ao redor dos objetos, Ã© ideal para aplicaÃ§Ãµes que precisam saber exatamente onde o alimento estÃ¡, como em robÃ´s de colheita ou sistemas automatizados. Por outro lado, exigiu bastante trabalho: levamos cerca de 4 horas de treino no Google Colab e ainda tivemos que rotular manualmente 200 imagens, o que consumiu vÃ¡rias horas.

JÃ¡ a CNN feita do zero seria uma boa opÃ§Ã£o para quem sÃ³ precisa classificar imagens, sem se preocupar com localizaÃ§Ã£o. Apesar de termos enfrentado problemas tÃ©cnicos no Colab e nÃ£o conseguimos rodar os testes por completo, com base em pesquisas, estimamos que ela teria uma acurÃ¡cia por volta de 85%, com um tempo de treino bem menor (uns 15 a 20 minutos). A vantagem aqui Ã© que ela Ã© mais fÃ¡cil de implementar e nÃ£o precisa de anotaÃ§Ãµes detalhadas nas imagens â€“ sÃ³ o nome da classe jÃ¡ basta.

Por fim, o YOLO padrÃ£o (prÃ©-treinado) nÃ£o funcionou bem para o nosso caso. Ele nÃ£o reconheceu corretamente as cenouras nem as batatas, em alguns casos, confundiu cenoura com laranja e batata com maÃ§Ã£. A inferÃªncia foi bem rÃ¡pida (em torno de 0,06 segundos por imagem), mas como ele nÃ£o foi treinado com nossos dados, acabou nÃ£o sendo Ãºtil sem um ajuste mais especÃ­fico.

## âš¡ Pontos Fortes e LimitaÃ§Ãµes

YOLO Customizado
  - âœ… Detecta e localiza objetos com alta precisÃ£o
  - âœ… AcurÃ¡cia alta (~92%) para cenoura e batata
  - âœ… Consegue identificar vÃ¡rios objetos na mesma imagem
  - âŒ Precisa de rotulagem manual demorada (6 a 8 horas)
  - âŒ Treinamento longo (~4 horas no Colab)
  - âŒ Mais complexo de ajustar e configurar

CNN do Zero
  - âœ… Mais simples de programar e treinar
  - âœ… SÃ³ precisa saber a classe da imagem (sem caixas de anotaÃ§Ã£o)
  - âœ… Treinamento mais rÃ¡pido (estimado em 15-20 min)
  - âŒ NÃ£o mostra onde o objeto estÃ¡ na imagem
  - âŒ Tivemos problemas tÃ©cnicos para rodar no Colab
  - âŒ NÃ£o Ã© ideal para imagens com mais de um objeto

YOLO PadrÃ£o
  - âœ… FÃ¡cil de usar e pronto para testar
  - âœ… InferÃªncia super rÃ¡pida (~0,06s por imagem)
  - âœ… Bom para testes e protÃ³tipos rÃ¡pidos
  - âŒ Fraco em precisÃ£o para nossas classes especÃ­ficas
  - âŒ Confunde facilmente objetos parecidos
  - âŒ NÃ£o serve para aplicaÃ§Ãµes mais especÃ­ficas sem ajuste


## ğŸ—ƒ HistÃ³rico de lanÃ§amentos

* 2.5.0 - 16/04//2025
    * 
* 1.4.0 - 15/04/2024


## ğŸ“‹ LicenÃ§a

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> estÃ¡ licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>


