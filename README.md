# FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de InformÃ¡tica e AdmnistraÃ§Ã£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# PROJETO FASE 6 â€“ O COMEÃ‡O DA REDE NEURAL

## Nome do grupo

## Grupo 11

## ğŸ‘¨â€ğŸ“ Integrantes: 
- <a href="https://www.linkedin.com/in/caiorcastro/">Caio Rodrigues Castro</a> 
- <a href="https://www.linkedin.com/in/celeste-leite-dos-santos-66352a24b/">Celeste Leite dos Santos</a> 
- <a href="https://www.linkedin.com/in/digitalmanagerfelipesoares/">Felipe Soares Nascimento</a>
- <a href="https://www.linkedin.com/in//">Wellington Nascimento de Brito</a>



## ğŸ‘©â€ğŸ« Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/in/leonardoorabona/">Leonardo Ruiz Orabona</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/in/profandregodoi/">AndrÃ© Godoi Chiovato</a>


## ğŸ“œ DescriÃ§Ã£o

Este projeto tem como objetivo aplicar e comparar diferentes abordagens de VisÃ£o Computacional na identificaÃ§Ã£o de alimentos (cenoura e batata), com foco em tarefas como classificaÃ§Ã£o e detecÃ§Ã£o de objetos. As soluÃ§Ãµes exploradas incluem:

- YOLOv8 Customizado (detecÃ§Ã£o e localizaÃ§Ã£o)
- YOLOv8 PrÃ©-treinado (sem fine-tuning)
- CNN do zero (classificaÃ§Ã£o)

Foram avaliadas acurÃ¡cia, tempo de treinamento, facilidade de implementaÃ§Ã£o e desempenho na inferÃªncia, considerando cenÃ¡rios reais como automaÃ§Ã£o agrÃ­cola.


## ğŸ“ Arquivos e VÃ­deo

- ğŸ”¬ **Notebook com a implementaÃ§Ã£o completa**: [Clique aqui para acessar o notebook no Colab](./src/FelipeSoares_Nascimento_RM560151_pbl_fase6_2.ipynb)
- ğŸ¥ **VÃ­deo demonstrativo**: [Assista aqui](LINK_DO_VÃDEO) 
- ğŸ“ **Dataset utilizado**: [Link para download do dataset](https://drive.google.com/file/d/1Yj9sYI9tum4c2c6ysYFp4-Cw4MS6WZCg/view?usp=drive_link)


## ğŸ”§ Como executar o cÃ³digo

### PrÃ©-requisitos:
- Google Colab ou ambiente Jupyter
- GPU recomendada para treinamento (T4 no Colab)
- Bibliotecas:
  - `ultralytics`
  - `torch`
  - `opencv-python`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`

(InstalaÃ§Ã£o automÃ¡tica via `pip install` dentro do notebook)

### Passo a passo:
1. Acesse o [notebook](https://colab.research.google.com/drive/1a4WzYzeUrFlogsQUIHSOoyc4NrMn-Juk?usp=sharing)
2. Monte o Google Drive com o dataset (instruÃ§Ã£o incluÃ­da no notebook).
3. [Link para download do dataset](https://drive.google.com/file/d/1Yj9sYI9tum4c2c6ysYFp4-Cw4MS6WZCg/view?usp=drive_link)

  - faÃ§a o download do arquivo zip "dataset-cenoura-batata.zip" e sua no seu drive o arquivo "dataset"
4. Execute as cÃ©lulas em sequÃªncia:
   - PreparaÃ§Ã£o dos dados
   - Treinamento dos modelos
   - InferÃªncia e avaliaÃ§Ã£o
5. Visualize os resultados diretamente nas saÃ­das do notebook com mÃ©tricas e imagens inferidas.

## ğŸ“Š Resultados comparativo das Abordagens


| Abordagem        | Facilidade | PrecisÃ£o | Tempo Treinamento | Tempo InferÃªncia |
|------------------|------------|----------|-------------------|------------------|
| YOLO Customizado | MÃ©dia      | 0,84     | 3h (60 Ã©pocas)    | 4,3s/imagem      |
| YOLO PadrÃ£o      | Alta       | 0,10     | 0s                | 12,7s/imagem      |
| CNN do Zero      | MÃ©dia      | 0,94     | 2min             | 25,25s/

## ğŸ¯ ConclusÃ£o
Nos nossos testes, vimos diferenÃ§as claras entre as abordagens que usamos para identificar alimentos, especialmente batatas e cenouras.

O YOLO customizado O YOLO customizado foi o que apresentou o melhor desempenho geral, uma precisÃ£o de 83,84%, indicando Ã³tima capacidade de identificar e localizar os objetos com precisÃ£o. Como ele desenha caixas ao redor dos alimentos, Ã© ideal para aplicaÃ§Ãµes em que Ã© necessÃ¡rio saber exatamente onde o alimento estÃ¡, como em robÃ´s de colheita ou sistemas de triagem automatizada. Por outro lado, exigiu um esforÃ§o considerÃ¡vel: foram 3 horas de treinamento no Google Colab e mais o tempo de anotaÃ§Ã£o manual de 200 imagens, o que demandou bastante dedicaÃ§Ã£o.

JÃ¡ a CNN feita do zero A CNN feita do zero foi eficiente para tarefas de classificaÃ§Ã£o simples (sem localizaÃ§Ã£o), com uma precisÃ£o estimada de 94%. Ela teve tempo de treinamento curto (cerca de 2 minutos) e exigiu apenas o nome da classe em cada imagem, nÃ£o foi necessÃ¡rio anotar com caixas. No entanto, sua inferÃªncia foi muito lenta (25,2 segundos por imagem), o que limita seu uso em sistemas em tempo real.

Por fim, o YOLO padrÃ£o, mesmo sem treinamento com nossos dados, foi capaz de reconhecer alguns objetos do nosso conjunto de teste, como cenouras, mas de forma inconsistente. Em vÃ¡rios casos, confundiu cenoura com laranja e batata com maÃ§Ã£, o que mostra que nÃ£o estava adaptado ao nosso domÃ­nio especÃ­fico sua precisÃ£o estimado foi de aproximadamente 10%, o que Ã© considerado baixo.

## âš¡ Pontos Fortes e LimitaÃ§Ãµes

YOLO Customizado
  - âœ… Detecta e localiza objetos com alta precisÃ£o
  - âœ… AcurÃ¡cia alta (~84%) para cenoura e batata
  - âœ… Consegue identificar vÃ¡rios objetos na mesma imagem
  - âŒ Precisa de rotulagem manual demorada (2 a 3 horas)
  - âŒ Treinamento longo (~1 horas no Colab)
  - âŒ Mais complexo de ajustar e configurar

CNN do Zero
  - âœ… Mais simples de programar e treinar
  - âœ… SÃ³ precisa saber a classe da imagem (sem caixas de anotaÃ§Ã£o)
  - âœ… Treinamento mais rÃ¡pido (estimado em 1-2 min)
  - âŒ NÃ£o mostra onde o objeto estÃ¡ na imagem
  - âŒ Tivemos problemas tÃ©cnicos para rodar no Colab
  - âŒ NÃ£o Ã© ideal para imagens com mais de um objeto

YOLO PadrÃ£o
  - âœ… FÃ¡cil de usar e pronto para testar
  - âœ… Bom para testes e protÃ³tipos rÃ¡pidos
  - âŒ Fraco em precisÃ£o para nossas classes especÃ­ficas
  - âŒ Confunde facilmente objetos parecidos
  - âŒ NÃ£o serve para aplicaÃ§Ãµes mais especÃ­ficas sem ajuste


## ğŸ—ƒ HistÃ³rico de lanÃ§amentos

* 2.5.0 - 16/04//2025
    * 
* 1.4.0 - 15/04/2024


## ğŸ“‹ LicenÃ§a

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> estÃ¡ licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>


